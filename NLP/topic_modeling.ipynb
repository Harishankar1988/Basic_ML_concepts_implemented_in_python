{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modeling",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOl44tG7H/Jw4Pvy8tVE+G0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harishankar1988/topic_modelling_sklearn_lsa_nmf_lda/blob/master/topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oolBKrmUS8mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apart from NMF rest parts are copied from sklearn website\n",
        "#This has been originally authored by \n",
        "#Olivier Grisel <olivier.grisel@ensta.org>, Lars Buitinck and Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
        "\n",
        "from time import time\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbZHuS7UUhDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPbahhHDUmil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Bkky8bU2BV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5286ddd-ab85-4eb2-ca73-50037f226b72"
      },
      "source": [
        "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
        "# to filter out useless terms early on: the posts are stripped of headers,\n",
        "# footers and quoted replies, and common English words, words occurring in\n",
        "# only one document or in at least 95% of the documents are removed.\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
        "                             remove=('headers', 'footers', 'quotes'),\n",
        "                             return_X_y=True)\n",
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "done in 1.440s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y0dEcKmU_qM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5127dd36-bc7e-4172-d894-8150bf6baec8"
      },
      "source": [
        "# Use tf-idf features for NMF.\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,\n",
        "                                   stop_words='english')\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "# Use tf (raw term count) features for LDA.\n",
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                max_features=n_features,\n",
        "                                stop_words='english')\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting tf-idf features for NMF...\n",
            "done in 0.345s.\n",
            "Extracting tf features for LDA...\n",
            "done in 0.336s.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDZhplpjVGxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e29ea8ba-f1b3-485a-c967-4a90913e7079"
      },
      "source": [
        "# Fit the NMF model\n",
        "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
            "done in 0.357s.\n",
            "\n",
            "Topics in NMF model (Frobenius norm):\n",
            "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
            "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
            "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
            "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
            "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
            "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
            "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
            "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
            "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
            "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmOgIlosVPWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "767a86e4-3b70-4fc7-d2b4-29f7c5a6a2c1"
      },
      "source": [
        "# Fit the NMF model\n",
        "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
        "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5).fit(tfidf)\n",
        "\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
        "\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
            "done in 1.504s.\n",
            "\n",
            "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
            "Topic #0: people don just like think did say time make know really right said things way ve course didn question probably\n",
            "Topic #1: windows help thanks using hi looking info video dos pc does anybody ftp appreciated mail know advance available use card\n",
            "Topic #2: god does jesus true book christian bible christians religion faith believe life church christ says know read exist lord people\n",
            "Topic #3: thanks know bike interested mail like new car edu heard just price list email hear want cars thing sounds reply\n",
            "Topic #4: 10 00 sale time power 12 new 15 year 30 offer condition 14 16 model 11 monitor 100 old 25\n",
            "Topic #5: space government number public data states earth security water research nasa general 1993 phone information science technology provide blood internet\n",
            "Topic #6: edu file com program soon try window problem remember files sun send library article mike wrong think code win manager\n",
            "Topic #7: game team year games play win season points world division won players nhl flyers toronto case cubs teams ll record\n",
            "Topic #8: drive think hard software disk drives apple computer mac need scsi card don problem read floppy post cable going ii\n",
            "Topic #9: use good just key chip got like ll way clipper doesn keys don better speed stuff want sure going need\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7CjYgwUVSyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b93ac7db-0b56-43f3-bfe4-df562761467c"
      },
      "source": [
        "print(\"Fitting the LSA model with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "lsa = svd.fit(tfidf)\n",
        "print_top_words(lsa, tfidf_feature_names, n_top_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the LSA model with tf-idf features, n_samples=2000 and n_features=1000...\n",
            "Topic #0: just like don know people think does good use time new god way ve want make thanks need really say\n",
            "Topic #1: god people think just jesus don bible say law did government life believe christian faith christians said christ agree religion\n",
            "Topic #2: god does thanks jesus know bible windows file faith christian mail christians edu advance hi christ help anybody info true\n",
            "Topic #3: edu thanks game know mail interested car like bike team new games email advance year send soon price list 00\n",
            "Topic #4: god drive game year windows 10 00 file team power problem software jesus good disk games new win 11 play\n",
            "Topic #5: edu god com 00 key soon chip government university new drive information sale law internet 10 send clipper phone car\n",
            "Topic #6: edu file think windows program soon files ftp win game window team pub problem space mit try com mike play\n",
            "Topic #7: game key team games looking does chip year thanks government play win keys encryption clipper players 00 season 10 nhl\n",
            "Topic #8: drive think drives don software hard card disk people game mac chip floppy computer apple need going pc mb scsi\n",
            "Topic #9: key god edu game chip use car good keys clipper does encryption like soon just team way doesn games window\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGO3oOvVXAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "09cd9510-3b7a-4262-856f-556590c1afe2"
      },
      "source": [
        "print(\"Fitting LDA models with tf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in LDA model:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
            "done in 4.051s.\n",
            "\n",
            "Topics in LDA model:\n",
            "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
            "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
            "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
            "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
            "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
            "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
            "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
            "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
            "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
            "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}